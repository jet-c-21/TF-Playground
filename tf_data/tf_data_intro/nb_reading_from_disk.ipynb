{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58dbabed-7c37-439d-8ae6-73143934e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from imutils import paths\n",
    "from tensorflow.data import AUTOTUNE\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from pyimagesearch.helpers import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902a9829-a671-48d5-b0d4-7cf021b97dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(imagePath):\n",
    "    \"\"\"\n",
    "    read the image from disk, decode it, resize it,\n",
    "    and scale the pixels intensities to the range [0, 1]\n",
    "\n",
    "    :param imagePath:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, (96, 96)) / 255.0\n",
    "\n",
    "    # grab the label and encode it\n",
    "    label = tf.strings.split(imagePath, os.path.sep)[-2]\n",
    "    oneHot = label == classNames\n",
    "    encodedLabel = tf.argmax(oneHot)\n",
    "\n",
    "    # return the image and the integer encoded label\n",
    "    return image, encodedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4e7c7d-67ba-43ab-b29d-7989be771572",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'fruits'\n",
    "\n",
    "# initialize batch size and number of steps\n",
    "BS = 64\n",
    "NUM_STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d691c72-0478-40fa-9522-cf22e0ecd136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading image paths...\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images in our dataset directory and grab all unique class names\n",
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(data_dir))\n",
    "classNames = np.array(sorted(os.listdir(data_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34d09a3-d677-45a0-b2d1-49ef3d8ffedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating a ImageDataGenerator object...\n",
      "Found 6688 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a standard image generator object\n",
    "print(\"[INFO] creating a ImageDataGenerator object...\")\n",
    "imageGen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "dataGen = imageGen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(96, 96),\n",
    "    batch_size=BS,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d66e4d-46a0-46c3-ac14-828ca6ead13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# benchmark the image data generator and display the number of data points generated, \n",
    "# along with the time taken to perform the operation\n",
    "# '''\n",
    "# totalTime = benchmark(dataGen, NUM_STEPS)\n",
    "# print(f\"[INFO] ImageDataGenerator generated {BS * NUM_STEPS} images in {totalTime:.2f} seconds...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5fc95ce-1aac-4cdb-a563-445d63ba44e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating a tf.data input pipeline..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 14:59:25.245128: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# build the dataset and data input pipeline\n",
    "print(\"[INFO] creating a tf.data input pipeline..\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices(imagePaths)\n",
    "dataset = dataset.shuffle(1024).map(load_images, num_parallel_calls=AUTOTUNE).cache().repeat().batch(BS).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f621c99-0c23-4fe7-b51a-0c2c0f06c777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] tf.data generated 64000 images in 22.67 seconds...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "create a dataset iterator, benchmark the tf.data pipeline, \n",
    "and display the number of data points generated, along with the time taken\n",
    "'''\n",
    "datasetGen = iter(dataset)\n",
    "totalTime = benchmark(datasetGen, NUM_STEPS)\n",
    "print(f\"[INFO] tf.data generated {BS * NUM_STEPS} images in {totalTime:.2f} seconds...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa2e62a-f154-4c0b-9b98-f83d7e80c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = imagePaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa394136-3842-4910-bbd1-438653047e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_images(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34478aa8-7a41-4258-83dd-59558c92b8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(96, 96, 3), dtype=float32, numpy=\n",
       "array([[[0.00000000e+00, 3.92156886e-03, 1.96078438e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 7.84313772e-03],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.38235301e-01, 1.64705887e-01, 1.75980389e-01],\n",
       "        [1.21568628e-01, 3.72549035e-02, 1.47058824e-02],\n",
       "        [1.85784310e-01, 1.60784319e-01, 1.03431374e-01]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 1.56862754e-02],\n",
       "        [0.00000000e+00, 4.90196107e-04, 8.33333377e-03],\n",
       "        [0.00000000e+00, 3.92156886e-03, 0.00000000e+00],\n",
       "        ...,\n",
       "        [5.62745094e-01, 6.43137276e-01, 6.82843149e-01],\n",
       "        [1.34803921e-01, 9.65686291e-02, 8.77451003e-02],\n",
       "        [7.20588267e-02, 1.91176478e-02, 4.41176491e-03]],\n",
       "\n",
       "       [[0.00000000e+00, 4.90196107e-04, 8.33333377e-03],\n",
       "        [0.00000000e+00, 0.00000000e+00, 7.84313772e-03],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [1.95098042e-01, 2.93627441e-01, 2.67647058e-01],\n",
       "        [1.20098040e-01, 8.43137279e-02, 4.75490205e-02],\n",
       "        [1.21568628e-01, 1.15686275e-01, 9.55882370e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[4.66666669e-01, 1.82843134e-01, 8.18627477e-02],\n",
       "        [6.34313703e-01, 4.73039210e-01, 3.57843131e-01],\n",
       "        [5.12745082e-01, 2.52450973e-01, 6.71568662e-02],\n",
       "        ...,\n",
       "        [2.84313738e-01, 4.42156851e-01, 3.42156857e-01],\n",
       "        [2.01470584e-01, 3.54901969e-01, 2.50490189e-01],\n",
       "        [2.11274505e-01, 3.50980401e-01, 2.56862760e-01]],\n",
       "\n",
       "       [[4.72058833e-01, 1.89215690e-01, 3.08823530e-02],\n",
       "        [4.79901969e-01, 1.62254900e-01, 4.60784324e-02],\n",
       "        [4.59313720e-01, 1.19607843e-01, 0.00000000e+00],\n",
       "        ...,\n",
       "        [4.00490195e-01, 5.83333313e-01, 5.21078408e-01],\n",
       "        [3.88235301e-01, 5.63725471e-01, 4.85294104e-01],\n",
       "        [3.60294104e-01, 5.29411793e-01, 4.87745106e-01]],\n",
       "\n",
       "       [[5.63725471e-01, 3.20098042e-01, 2.32352942e-01],\n",
       "        [5.15686274e-01, 2.14215681e-01, 6.37254938e-02],\n",
       "        [4.25490201e-01, 6.91176504e-02, 0.00000000e+00],\n",
       "        ...,\n",
       "        [4.58823532e-01, 6.63725495e-01, 5.94607830e-01],\n",
       "        [4.25490201e-01, 6.26470566e-01, 5.76960802e-01],\n",
       "        [3.40686262e-01, 5.25980413e-01, 5.30882359e-01]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12e60ed8-c3fd-4f31-95fe-140df79a73a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9ad44-4ce7-4680-8e76-fe38ef5098f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OME",
   "language": "python",
   "name": "ome"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
