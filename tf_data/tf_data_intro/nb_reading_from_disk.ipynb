{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58dbabed-7c37-439d-8ae6-73143934e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from imutils import paths\n",
    "from tensorflow.data import AUTOTUNE\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from pyimagesearch.helpers import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "902a9829-a671-48d5-b0d4-7cf021b97dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(imagePath):\n",
    "    \"\"\"\n",
    "    read the image from disk, decode it, resize it,\n",
    "    and scale the pixels intensities to the range [0, 1]\n",
    "\n",
    "    :param imagePath:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.resize(image, (96, 96)) / 255.0\n",
    "\n",
    "    # grab the label and encode it\n",
    "    label = tf.strings.split(imagePath, os.path.sep)[-2]\n",
    "    oneHot = label == classNames\n",
    "    encodedLabel = tf.argmax(oneHot)\n",
    "\n",
    "    # return the image and the integer encoded label\n",
    "    return image, encodedLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4e7c7d-67ba-43ab-b29d-7989be771572",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'fruits'\n",
    "\n",
    "# initialize batch size and number of steps\n",
    "BS = 64\n",
    "NUM_STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d691c72-0478-40fa-9522-cf22e0ecd136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading image paths...\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images in our dataset directory and grab all unique class names\n",
    "print(\"[INFO] loading image paths...\")\n",
    "imagePaths = list(paths.list_images(data_dir))\n",
    "classNames = np.array(sorted(os.listdir(data_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b34d09a3-d677-45a0-b2d1-49ef3d8ffedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating a ImageDataGenerator object...\n",
      "Found 6688 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a standard image generator object\n",
    "print(\"[INFO] creating a ImageDataGenerator object...\")\n",
    "imageGen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "dataGen = imageGen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(96, 96),\n",
    "    batch_size=BS,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d66e4d-46a0-46c3-ac14-828ca6ead13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# benchmark the image data generator and display the number of data points generated, \n",
    "# along with the time taken to perform the operation\n",
    "# '''\n",
    "# totalTime = benchmark(dataGen, NUM_STEPS)\n",
    "# print(f\"[INFO] ImageDataGenerator generated {BS * NUM_STEPS} images in {totalTime:.2f} seconds...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5fc95ce-1aac-4cdb-a563-445d63ba44e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating a tf.data input pipeline..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 15:09:46.796699: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# build the dataset and data input pipeline\n",
    "print(\"[INFO] creating a tf.data input pipeline..\")\n",
    "dataset = tf.data.Dataset.from_tensor_slices(imagePaths)\n",
    "dataset = dataset.shuffle(1024).map(load_images, num_parallel_calls=AUTOTUNE).cache().repeat().batch(BS).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f621c99-0c23-4fe7-b51a-0c2c0f06c777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] tf.data generated 64000 images in 35.46 seconds...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "create a dataset iterator, benchmark the tf.data pipeline, \n",
    "and display the number of data points generated, along with the time taken\n",
    "'''\n",
    "datasetGen = iter(dataset)\n",
    "totalTime = benchmark(datasetGen, NUM_STEPS)\n",
    "print(f\"[INFO] tf.data generated {BS * NUM_STEPS} images in {totalTime:.2f} seconds...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aa2e62a-f154-4c0b-9b98-f83d7e80c110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'fruits/apple/apple_941.jpg'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = imagePaths[0]\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa394136-3842-4910-bbd1-438653047e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_images(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34478aa8-7a41-4258-83dd-59558c92b8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(96, 96, 3), dtype=float32, numpy=\narray([[[0.00000000e+00, 3.92156886e-03, 1.96078438e-02],\n        [0.00000000e+00, 0.00000000e+00, 7.84313772e-03],\n        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n        ...,\n        [1.38235301e-01, 1.64705887e-01, 1.75980389e-01],\n        [1.21568628e-01, 3.72549035e-02, 1.47058824e-02],\n        [1.85784310e-01, 1.60784319e-01, 1.03431374e-01]],\n\n       [[0.00000000e+00, 0.00000000e+00, 1.56862754e-02],\n        [0.00000000e+00, 4.90196107e-04, 8.33333377e-03],\n        [0.00000000e+00, 3.92156886e-03, 0.00000000e+00],\n        ...,\n        [5.62745094e-01, 6.43137276e-01, 6.82843149e-01],\n        [1.34803921e-01, 9.65686291e-02, 8.77451003e-02],\n        [7.20588267e-02, 1.91176478e-02, 4.41176491e-03]],\n\n       [[0.00000000e+00, 4.90196107e-04, 8.33333377e-03],\n        [0.00000000e+00, 0.00000000e+00, 7.84313772e-03],\n        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n        ...,\n        [1.95098042e-01, 2.93627441e-01, 2.67647058e-01],\n        [1.20098040e-01, 8.43137279e-02, 4.75490205e-02],\n        [1.21568628e-01, 1.15686275e-01, 9.55882370e-02]],\n\n       ...,\n\n       [[4.66666669e-01, 1.82843134e-01, 8.18627477e-02],\n        [6.34313703e-01, 4.73039210e-01, 3.57843131e-01],\n        [5.12745082e-01, 2.52450973e-01, 6.71568662e-02],\n        ...,\n        [2.84313738e-01, 4.42156851e-01, 3.42156857e-01],\n        [2.01470584e-01, 3.54901969e-01, 2.50490189e-01],\n        [2.11274505e-01, 3.50980401e-01, 2.56862760e-01]],\n\n       [[4.72058833e-01, 1.89215690e-01, 3.08823530e-02],\n        [4.79901969e-01, 1.62254900e-01, 4.60784324e-02],\n        [4.59313720e-01, 1.19607843e-01, 0.00000000e+00],\n        ...,\n        [4.00490195e-01, 5.83333313e-01, 5.21078408e-01],\n        [3.88235301e-01, 5.63725471e-01, 4.85294104e-01],\n        [3.60294104e-01, 5.29411793e-01, 4.87745106e-01]],\n\n       [[5.63725471e-01, 3.20098042e-01, 2.32352942e-01],\n        [5.15686274e-01, 2.14215681e-01, 6.37254938e-02],\n        [4.25490201e-01, 6.91176504e-02, 0.00000000e+00],\n        ...,\n        [4.58823532e-01, 6.63725495e-01, 5.94607830e-01],\n        [4.25490201e-01, 6.26470566e-01, 5.76960802e-01],\n        [3.40686262e-01, 5.25980413e-01, 5.30882359e-01]]], dtype=float32)>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12e60ed8-c3fd-4f31-95fe-140df79a73a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08b9ad44-4ce7-4680-8e76-fe38ef5098f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_read_img(img_path):\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    print(image)\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[  0   0   4]\n",
      "  [  0   0   4]\n",
      "  [  0   0   4]\n",
      "  ...\n",
      "  [ 26  22  13]\n",
      "  [ 39  39  27]\n",
      "  [ 54  56  42]]\n",
      "\n",
      " [[  0   0   4]\n",
      "  [  0   0   4]\n",
      "  [  0   1   5]\n",
      "  ...\n",
      "  [ 56  50  38]\n",
      "  [ 45  43  30]\n",
      "  [ 50  51  37]]\n",
      "\n",
      " [[  0   0   4]\n",
      "  [  0   1   5]\n",
      "  [  0   1   5]\n",
      "  ...\n",
      "  [ 33  26   7]\n",
      "  [ 44  38  24]\n",
      "  [ 40  36  25]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[176 120  97]\n",
      "  [188 134 108]\n",
      "  [185 131 103]\n",
      "  ...\n",
      "  [ 95 141 141]\n",
      "  [ 86 132 132]\n",
      "  [ 73 119 117]]\n",
      "\n",
      " [[117  48  33]\n",
      "  [129  62  45]\n",
      "  [119  52  33]\n",
      "  ...\n",
      "  [ 82 130 132]\n",
      "  [ 61 106 109]\n",
      "  [ 42  88  88]]\n",
      "\n",
      " [[113  36  26]\n",
      "  [106  32  19]\n",
      "  [108  34  21]\n",
      "  ...\n",
      "  [ 51  99 103]\n",
      "  [ 35  80  83]\n",
      "  [ 32  77  80]]], shape=(360, 480, 3), dtype=uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(360, 480, 3), dtype=float32, numpy=\narray([[[0.        , 0.        , 0.01568628],\n        [0.        , 0.        , 0.01568628],\n        [0.        , 0.        , 0.01568628],\n        ...,\n        [0.10196079, 0.08627451, 0.0509804 ],\n        [0.15294118, 0.15294118, 0.10588236],\n        [0.21176472, 0.21960786, 0.16470589]],\n\n       [[0.        , 0.        , 0.01568628],\n        [0.        , 0.        , 0.01568628],\n        [0.        , 0.00392157, 0.01960784],\n        ...,\n        [0.21960786, 0.19607845, 0.14901961],\n        [0.1764706 , 0.16862746, 0.11764707],\n        [0.19607845, 0.20000002, 0.14509805]],\n\n       [[0.        , 0.        , 0.01568628],\n        [0.        , 0.00392157, 0.01960784],\n        [0.        , 0.00392157, 0.01960784],\n        ...,\n        [0.12941177, 0.10196079, 0.02745098],\n        [0.17254902, 0.14901961, 0.09411766],\n        [0.15686275, 0.14117648, 0.09803922]],\n\n       ...,\n\n       [[0.6901961 , 0.47058827, 0.3803922 ],\n        [0.7372549 , 0.5254902 , 0.42352945],\n        [0.7254902 , 0.5137255 , 0.4039216 ],\n        ...,\n        [0.37254903, 0.5529412 , 0.5529412 ],\n        [0.3372549 , 0.5176471 , 0.5176471 ],\n        [0.28627452, 0.4666667 , 0.45882356]],\n\n       [[0.45882356, 0.18823531, 0.12941177],\n        [0.5058824 , 0.24313727, 0.1764706 ],\n        [0.4666667 , 0.20392159, 0.12941177],\n        ...,\n        [0.32156864, 0.50980395, 0.5176471 ],\n        [0.2392157 , 0.4156863 , 0.427451  ],\n        [0.16470589, 0.34509805, 0.34509805]],\n\n       [[0.4431373 , 0.14117648, 0.10196079],\n        [0.4156863 , 0.1254902 , 0.07450981],\n        [0.42352945, 0.13333334, 0.08235294],\n        ...,\n        [0.20000002, 0.38823533, 0.4039216 ],\n        [0.13725491, 0.3137255 , 0.3254902 ],\n        [0.1254902 , 0.3019608 , 0.3137255 ]]], dtype=float32)>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_read_img(img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "qq = tf.constant(52, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "52.0"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OME",
   "language": "python",
   "name": "ome"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}